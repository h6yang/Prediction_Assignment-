head(melted)
rm(list = ls())
library(ggplot2)
library(plyr)
library(TukeyC)
library(bear)
library(multcompView)
SEM<-read.csv("/Users/hai/Downloads/SEM14.csv",sep=",",header=TRUE )
attach(SEM)
head(SEM)
summary(SEM)
library(ggplot2)
library(plyr)
library(reshape2)
id = id
SEM$group <- Treatment
SEM$value <- Wax_um
SEM$variable <- Location
melted <- melt(SEM, id.vars=c("id", "group"))
head(melted)
head(SEM)
rm(list = ls())
library(ggplot2)
library(plyr)
library(TukeyC)
library(bear)
library(multcompView)
SEM<-read.csv("/Users/hai/Downloads/SEM14.csv",sep=",",header=TRUE )
attach(SEM)
head(SEM)
summary(SEM)
library(ggplot2)
library(plyr)
library(reshape2)
id = id
SEM$value <- Wax_um
SEM$variable <- Location
SEM$group <- Treatment
melted <- melt(SEM, id.vars=c("id", "group"))
head(melted)
melted <- melt(data, id.vars=c("id", "group"))
head(melted)
melted
head(data)
n <- 10
group <- rep(1:4, n)
mass.means <- c(10, 20, 15, 30)
mass.sigma <- 4
score.means <- c(5, 5, 7, 4)
score.sigma <- 3
mass <- as.vector(model.matrix(~0+factor(group)) %*% mass.means) +
rnorm(n*4, 0, mass.sigma)
score <- as.vector(model.matrix(~0+factor(group)) %*% score.means) +
rnorm(n*4, 0, score.sigma)
data <- data.frame(id = 1:(n*4), group, mass, score)
head(data)
melted <- melt(data, id.vars=c("id", "group"))
head(melted)
head(data)
rm(list = ls())
library(ggplot2)
library(plyr)
library(TukeyC)
library(bear)
library(multcompView)
SEM<-read.csv("/Users/hai/Downloads/SEM14.csv",sep=",",header=TRUE )
attach(SEM)
head(SEM)
summary(SEM)
library(ggplot2)
library(plyr)
library(reshape2)
id = id
SEM$value <- Wax_um
SEM$variable <- Location
SEM$group <- Treatment
means <- ddply(melted, c("group", "variable"), summarise,
mean=mean(value))
means <- ddply(SEM, c("group", "variable"), summarise,
mean=mean(value))
means.barplot <- qplot(x=group, y=mean, fill=variable,
data=means, geom="bar", stat="identity",
position="dodge")
melted <- melt(data, id.vars=c("id", "group"))
means <- ddply(melted, c("group", "variable"), summarise,
mean=mean(value))
means.barplot <- qplot(x=group, y=mean, fill=variable,
data=means, geom="bar", stat="identity",
position="dodge")
n <- 10
group <- rep(1:4, n)
mass.means <- c(10, 20, 15, 30)
mass.sigma <- 4
score.means <- c(5, 5, 7, 4)
score.sigma <- 3
mass <- as.vector(model.matrix(~0+factor(group)) %*% mass.means) +
rnorm(n*4, 0, mass.sigma)
score <- as.vector(model.matrix(~0+factor(group)) %*% score.means) +
rnorm(n*4, 0, score.sigma)
data <- data.frame(id = 1:(n*4), group, mass, score)
head(data)
melted <- melt(data, id.vars=c("id", "group"))
means <- ddply(melted, c("group", "variable"), summarise,
mean=mean(value))
means.barplot <- qplot(x=group, y=mean, fill=variable,
data=means, geom="bar", stat="identity",
position="dodge")
means.sem <- ddply(melted, c("group", "variable"), summarise,
mean=mean(value), sem=sd(value)/sqrt(length(value)))
means.sem <- transform(means.sem, lower=mean-sem, upper=mean+sem)
means.barplot + geom_errorbar(aes(ymax=upper,
ymin=lower),
position=position_dodge(0.9),
data=means.sem)
n <- 10
group <- rep(1:4, n)
mass.means <- c(10, 20, 15, 30)
mass.sigma <- 4
score.means <- c(5, 5, 7, 4)
score.sigma <- 3
mass <- as.vector(model.matrix(~0+factor(group)) %*% mass.means) +
rnorm(n*4, 0, mass.sigma)
score <- as.vector(model.matrix(~0+factor(group)) %*% score.means) +
rnorm(n*4, 0, score.sigma)
data <- data.frame(id = 1:(n*4), group, mass, score)
head(data)
melted <- melt(data, id.vars=c("id", "group"))
means <- ddply(melted, c("group", "variable"), summarise,
mean=mean(value))
means.barplot <- qplot(x=group, y=mean, fill=variable,
data=means, geom="bar", stat="identity",
position="dodge")
head(means)
rm(list = ls())
library(ggplot2)
library(plyr)
library(TukeyC)
library(bear)
library(multcompView)
SEM<-read.csv("/Users/hai/Downloads/SEM14.csv",sep=",",header=TRUE )
attach(SEM)
head(SEM)
summary(SEM)
wax<-lm(Wax_um~Treatment+Stage+Location,data=SEM)
anova(wax)
summary(wax)
wax_summ<- summarySE(SEM, measurevar="Wax_um", groupvars=c("Treatment"))
wax_summ
plot(wax)
library(ggplot2)
library(plyr)
library(reshape2)
id = id
SEM$value <- Wax_um
SEM$variable <- Location
SEM$group <- Treatment
means <- ddply(SEM, c("group", "variable"), summarise,
mean=mean(value))
head(means)
means.barplot <- qplot(x=group, y=mean, fill=variable,
data=means)
head(means.barplot)
qplot(x=group, y=mean, fill=variable,
data=means, geom="bar")
is.numeric(mean)
head(means)
head(means$mean)
is.numeric(means$mean)
head(means)
qplot(x=group, y=mean, fill=variable,
data=means, geom="bar")
qplot(x=group, y=means$mean, fill=variable,
data=means, geom="bar")
is.numeric(means$mean)
qplot(x=group, y=means$mean, fill=variable,
data=means)
qplot(x=group, y=means$mean, fill=variable,
data=means, geom="bar")
qplot(x=group, y=means$mean, fill=variable,
data=means, stat="identity")
qplot(x=group, y=means$mean, fill=variable,
data=means, position="dodge")
head(SEM)
means <- ddply(SEM, c("group", "variable","Stage"), summarise,
mean=mean(value))
head(means)
means.sem <- ddply(melted, c("group", "variable""Stage"), summarise,
mean=mean(value), sem=sd(value)/sqrt(length(value)))
means.sem <- ddply(SEM, c("group", "variable""Stage"), summarise,
mean=mean(value), sem=sd(value)/sqrt(length(value)))
means.sem <- ddply(SEM, c("group", "variable","Stage"), summarise,
mean=mean(value), sem=sd(value)/sqrt(length(value)))
means <- ddply(SEM, c("group", "variable","Stage"), summarise,
means.sem <- ddply(SEM, c("group", "variable","Stage"), summarise,
mean=mean(value), sem=sd(value)/sqrt(length(value)))
head(means.sem)
means.sem <- transform(means.sem, lower=mean-sem, upper=mean+sem)
means.barplot + geom_errorbar(aes(ymax=upper,
ymin=lower),
position=position_dodge(0.9),
data=means.sem)
means.barplot <- qplot(x=group, y=means$mean, fill=variable, data=means,geom = "histogram", fill = color)
means.barplot <- qplot(x=group, y=means$mean, fill=variable, data=means,geom = "histogram", fill = color)
means.sem <- ddply(SEM, c("group", "variable","Stage"), summarise,
mean=mean(value), sem=sd(value)/sqrt(length(value)))
means.sem <- transform(means.sem, lower=mean-sem, upper=mean+sem)
means.barplot + geom_errorbar(aes(ymax=upper,
ymin=lower),
position=position_dodge(0.9),
data=means.sem)
qplot(x=group, y=means$mean, fill=variable, data=means,geom = "histogram", fill = color)
means.barplot <- qplot(x=group, y=means$mean, fill=variable, data=means,geom = "histogram")
qplot(x=group, y=means$mean, fill=variable, data=means,geom = "histogram")
means.barplot <- qplot(x=group, y=mean, fill=variable, data=means,geom = "histogram")
qplot(x=group, y=mean, fill=variable, data=means,geom = "histogram")
ggplot(data=SEM, aes(x=group, y=mean, fill=variable)) +
geom_bar(stat="identity", position=position_dodge())+
scale_fill_brewer(palette="Paired")+
theme_minimal()
ggplot(data=SEM, aes(x=group, y=mean, fill=variable))
head(SEM)
ggplot(data=means, aes(x=group, y=mean, fill=variable))
ggplot(data=means, aes(x=means$group, y=means$mean, fill=means$variable))
head(means$group)
head(means$mean)
head(means$variable)
n <- 10
group <- rep(1:4, n)
mass.means <- c(10, 20, 15, 30)
mass.sigma <- 4
score.means <- c(5, 5, 7, 4)
score.sigma <- 3
mass <- as.vector(model.matrix(~0+factor(group)) %*% mass.means) +
rnorm(n*4, 0, mass.sigma)
score <- as.vector(model.matrix(~0+factor(group)) %*% score.means) +
rnorm(n*4, 0, score.sigma)
data <- data.frame(id = 1:(n*4), group, mass, score)
head(data)
melted <- melt(data, id.vars=c("id", "group"))
means <- ddply(melted, c("group", "variable"), summarise,
mean=mean(value))
means.barplot <- qplot(x=group, y=mean, fill=variable,
data=means, geom="bar", stat="identity",
position="dodge")
means.sem <- ddply(melted, c("group", "variable"), summarise,
mean=mean(value), sem=sd(value)/sqrt(length(value)))
means.sem <- transform(means.sem, lower=mean-sem, upper=mean+sem)
means.barplot + geom_errorbar(aes(ymax=upper,
ymin=lower),
position=position_dodge(0.9),
693000*1.05^6
928686.3-693000
235686.3/6
78.65+34.65
113.3*1.08
175*121/70
70*1.05^30
70*1.03^30
249/3000
0.083*100000
install.packages("blastr")
source("https://bioconductor.org/biocLite.R")
biocLite(c("blastr"))
819/50
974/66
install.packages("bayesm")
qchisq(1-0.05, 1)
qchisq(1-0.0001, 1)
qchisq(1-0.0001, 1)
qnorm(1-0.05/2)
qchisq(1-0.0005, 1)
48500*6.6
# set a working directory
wd <- "/Users/jihoonkim/OneDrive\ -\ UC\ San\ Diego/CICT/"
setwd( wd )
# load a function file
source("CICT_func.R")
# load a data file
fname <- "CICTclean.csv"
da = read.table(fname, header=T, sep=",")
# load libraries
library( lme4 )
library( ggplot2 )
library( grid )
# derive variables
da$Accuracy <- da$AccuCorpus
da$Difficulty <-  log2(da$TotalAnnoCount)
da$Length <-   log2(da$TotalWordCount)
da$Time <- da$Duration
medianTotalWC <- median(da$TotalWordCount)
da$TotalWordCountGroup <- ifelse(da$TotalWordCount < 1000, '<1000', '>=1000')
3800+ 900+900+650+450
3000+1623+415+2034
3000+1623+415
2033.09+513
3800+900+650+650+100
1000+1623+415+1222
3000+1632+415
8000+1600*8
8000+1600*12
27000/5
3000+1632+415+2034
3000+1632+415
1000+2000+1632+415+1222
7000/12
584+1632+415
1300+900
11000+16000
1000+2546+1632+415+1222
2546+1222
1000+3768+1632+415
6000+1500*12
24000-1200
11000+16000+2034+3768
32802-24000
8*2000
install.packages("aylmer")
library(aylmer)
data(chess)
aylmer.test(chess)
head(chess)
allboards(chess)
maxlike(chess)
data(frogs)
x <- matrix(c(28,2,9,7,3,1,14,34,9,8,6,2),ncol=2)
data(iqd)
f <- function(x){x[1,1]}
table(allboards(iqd,1000,f))
as.pairwise(x)
a <- matrix(rpois(25,4),5,5)
rownames(a) <- letters[1:5]
colnames(a) <- letters[1:5]
as.pairwise(a)
data(iqd)
head(iqd)
aylmer.test(iqd)
data(frogs)
prob(frogs)
prob(frogs,use.brob=TRUE)
a <- matrix(0,5,5)
diag(a) <- NA
a[cbind(1:5 , c(2:5,1))] <- 4
best(a,control=list(maxit=10)) ## Answer should be all ones except the diagonal
best(a,func=function(x){x[1,2]},control=list(maxit=100))
data(gear)
is.1dof(gear)
aylmer.test(gear)
aylmer.test(gear,alternative="less")
18*30 -2*20
500+650
500+650+590+50+250
read.csv("https://ucsdcloud-my.sharepoint.com/personal/h6yang_ucsd_edu/_layouts/15/WopiFrame.aspx?sourcedoc=%7B1B066E5B-B0BC-4B60-B5BE-D3A3FACA680D%7D&file=simulate_dv.csv&action=default")
read.csv("https://ucsdcloud-my.sharepoint.com/personal/h6yang_ucsd_edu/_layouts/15/guestaccess.aspx?docid=11b066e5bb0bc4b60b5bed3a3faca680d&authkey=AW7jeRlz5UDf7g2NR7rZGtw&expiration=2017-06-30T21%3a04%3a37.000Z")
readLines("https://ucsdcloud-my.sharepoint.com/personal/h6yang_ucsd_edu/_layouts/15/guestaccess.aspx?docid=11b066e5bb0bc4b60b5bed3a3faca680d&authkey=AW7jeRlz5UDf7g2NR7rZGtw&expiration=2017-06-30T21%3a04%3a37.000Z")
0.18 -1.54+ 0.42+ 0.95
.01/4
2*(.18-.0025)^2 + 2*(-1.54-.0025)^2 + 2*(0.42-.0025)^2 + 2*(0.95-.0025)^2
2*(.18-.0025)^2 + 1*(-1.54-.0025)^2 + 3*(0.42-.0025)^2 + 1*(0.95-.0025)^2
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
lm(y~x)
library(mtcars)
data(mtcars)
lm(mpg~weight, data=mtcars)
head(mtcars)
lm(mpg~wt, data=mtcars)
x <- c(8.58, 10.46, 9.01, 9.64, 8.86)
summary(x)
str(x)
sd(x)
8.58-9.31
-.73/0.7511325
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
lm(y~x)
mean(x)
2*.18-1.54+.42*3-.95
-0.87/7
2*(.18-0.12)^2 + 1*(-1.54-0.12)^2 + 3*(0.42-0.12)^2 + 1*(0.95-0.12)^2
2*.18-1.54+.42*3+.95
1.03/7
data(mtcars)
head(mtcars)
lm(mpg~wt, data=mtcars)
x <- c(8.58, 10.46, 9.01, 9.64, 8.86)
summary(x)
str(x)
sd(x)
0.75-8.58
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
lm(y~x)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
mean(x)
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
fit <- lm(y~x)
summary(fit)
fit <- lm(mpg~wt, data=mtcars)
ci(fit)
mean(mtcars$wt)
fit <- lm(mpg~wt, data=mtcars)
mean(mtcars$wt)
predict(fit, 3.21725, interval="confidence")
confint(fit, 3.21725, level=0.95)
confint(fit, wt, level=0.95)
summary(fit)
mean(mtcars$wt)
-5.3445*3.21725+ 37.2851
-5.3445*3.21725+ 37.2851-2*3.046
predict(fit,data.frame(x=mean(x)), interval="confidence")
predict(fit,data.frame(x=mean(mtcars$wt)), interval="confidence")
predict(fit,data.frame(wt=mean(mtcars$wt)), interval="confidence")
-5.3445*3.21725+ 37.2851-1.96*3.046/sqrt(30)
-5.3445*3.21725+ 37.2851-1.96*3.046/sqrt(29)
??mtcars
predict(fit,data.frame(wt=3000)), interval="prediction")
predict(fit,data.frame(wt=3000), interval="prediction")
predict(fit,data.frame(wt=3), interval="prediction")
shortton <- mtcars$wt/2
fit <- lm(mtcars$mpg~shortton)
predict(fit,data.frame(shortton=1), interval="confidence")
fit <- lm(mtcars$mpg~shortton)
predict(fit,data.frame(shortton=1), interval="confidence")
summary(fit)
-10.689 -1.96*1.118/sqrt(30)
fit <- lm(mpg~wt, data=mtcars)
summary(fit)
fit_intercept <- lm(mpg~1, data=mtcars)
summary(fit_intercept)
workdir <- "/Users/hai/Documents/Personal/Data_Scientist_Learning/prediction_assignment_course_8"
setwd(workdir)
library(ggplot2)
workdir <- "/Users/hai/Documents/Personal/Data_Scientist_Learning/prediction_assignment_course_8"
setwd(workdir)
training <- read.csv("pml-training.csv", head=T)
head(training)
pairs(training[,1:10], col=training$classe)
pairs(training[,-1:-10], col=training$classe)
pairs(training[,8:11], col=training$classe)
head(training[,37])
pairs(training[,37:49], col=training$classe)
pairs(training[,37:40], col=training$classe)
dim(traning)
dim(training)
library(caret)
modelFit <- train(training$classe ~ ., method="glm",preProcess="pca",data=training)
summary(training$classe)
na.omit(training)
dim(na.omit(training))
training.pca <- prcomp(training,
center = TRUE,
scale. = TRUE)
training.pca <- prcomp(training[,6:159],
center = TRUE,
scale. = TRUE)
training.pca <- prcomp(training[,37:49],
center = TRUE,
scale. = TRUE)
print(training.pca)
plot(training.pca, type = "l")
summary(training.pca)
correlationMatrix <- cor(training)
nums <- sapply(training, is.numeric)
training[ , nums]
dim(training[ , nums])
correlationMatrix <- cor(training[ , nums])
correlationMatrix
print(correlationMatrix)
highlyCorrelated <- findCorrelation(correlationMatrix, cutoff=0.5)
findCorrelation(correlationMatrix, cutoff=0.5)
print(correlationMatrix)
highlyCorrelated <- findCorrelation(na.omit(correlationMatrix), cutoff=0.5)
print(highlyCorrelated)
na.omit(correlationMatrix)
highlyCorrelated <- findCorrelation(correlationMatrix[complete.cases(correlationMatrix),], cutoff=0.5)
print(highlyCorrelated)
print(correlationMatrix)
nums <- sapply(correlationMatrix, is.numeric)
correlationMatrix[ , nums]
nums
correlationMatrix[ , nums]
dim(training[ , nums])
nums <- sapply(training, is.numeric)
training[ , nums]
dim(training[ , nums])
123*122
nums <- sapply(correlationMatrix, is.numeric)
nums
correlationMatrix[ , nums]
correlationMatrix[,sapply(correlationMatrix,is.numeric)]
myDataNZV <- nearZeroVar(training, saveMetrics=TRUE)
myDataNZV
myDataNZV[1,nzv=="TRUE"]
myDataNZV[1,myDataNZV$nzv=="TRUE"]
colnames(myDataNZV)
str(myDataNZV$nzv)
myDataNZV[myDataNZV[,"zeroVar"] > 0, ]
myDataNZV[myDataNZV[,"nzv"] > 0, ]
dim(myDataNZV[1,myDataNZV$nzv=="FALSE"])
myDataNZV[myDataNZV[,"nzv"] > 0, ]
myDataNZV[1,myDataNZV$nzv=="TRUE"]
dim(myDataNZV[myDataNZV[,"nzv"] < 0, ])
dim(myDataNZV[myDataNZV[,"nzv"] > 0, ])
dim(training)
dim(myDataNZV[myDataNZV[,"nzv"] > 0, ])
dim(myDataNZV[myDataNZV[,"nzv"] <= 0, ])
myDataNZV[myDataNZV[,"nzv"] <= 0, ]
dim(myDataNZV[myDataNZV[,"nzv"] <= 0,1 ])
myDataNZV[myDataNZV[,"nzv"] <= 0,1 ]
colnames(myDataNZV[myDataNZV[,"nzv"] <= 0, ])
rownames(myDataNZV[myDataNZV[,"nzv"] <= 0, ])
